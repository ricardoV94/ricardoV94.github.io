<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>probability on As long as everything adds up to one</title><link>https://ricardov94.github.io/categories/probability/</link><description>Recent content in probability on As long as everything adds up to one</description><generator>Hugo -- gohugo.io</generator><language>en-us</language><lastBuildDate>Mon, 13 Nov 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://ricardov94.github.io/categories/probability/index.xml" rel="self" type="application/rss+xml"/><item><title>Successive Wins, from Fifty Challenging Problems in Probability</title><link>https://ricardov94.github.io/posts/successive_wins/</link><pubDate>Mon, 13 Nov 2023 00:00:00 +0000</pubDate><guid>https://ricardov94.github.io/posts/successive_wins/</guid><description>The author poses the following problem:
To encourage Elmer’s promising tennis career, his father offers him a prize if he wins (at least) two tennis sets in a row in a three-set series to be played with his father and the club champion alternately: father-champion-father (FCF) or champion-father-champion (CFC), according to Elmer’s choice. The champion is a better player than Elmer’s father. Which series should Elmer choose?
The answer is CFC, and the author emphasizes, after listing all the possible sequences, the importance of the middle match where a victory must absolutely be scored.</description></item><item><title>A simple Sequential Monte Carlo algorithm for posterior approximation</title><link>https://ricardov94.github.io/posts/smc_basic_algorithm/</link><pubDate>Fri, 06 Aug 2021 00:00:00 +0000</pubDate><guid>https://ricardov94.github.io/posts/smc_basic_algorithm/</guid><description>Introduction # Sequential Monte Carlo (SMC) can be used to take samples from posterior distributions, as an alternative to popular methods such as Markov Chain Monte Carlo (MCMC) like Metropolis-Hastings, Gibbs Sampling or more state-of-the-art Hamiltonian Monte Carlo (HMC) and No-U-Turn Sampler (NUTS).
Instead of creating a single Markov Chain, SMC works by keeping track of a large population of samples, which, in a similar spirit to Genetic Algorithms can be &amp;ldquo;selected&amp;rdquo; and &amp;ldquo;mutated&amp;rdquo; to evolve a better &amp;ldquo;fit&amp;rdquo; to the posterior distribution.</description></item><item><title>A most unprincipled derivation of the gamma distribution</title><link>https://ricardov94.github.io/posts/gamma_distribution/</link><pubDate>Tue, 13 Jul 2021 00:00:00 +0000</pubDate><guid>https://ricardov94.github.io/posts/gamma_distribution/</guid><description>Introduction # In this article I will derive the gamma distribution in a most unprincipled way.
Why? First, there are many good resources out there explaining how to derive the gamma distribution from first principles, usually involving these idealized things called poisson processes. These are great sources and I would definitely recommend them. This one by Aerin Kim is amazing.
However, more often than not, people use gamma distributions in real world problems for much more mundane reasons: It&amp;rsquo;s a well behaved yet flexible positive continuous distribution.</description></item></channel></rss>