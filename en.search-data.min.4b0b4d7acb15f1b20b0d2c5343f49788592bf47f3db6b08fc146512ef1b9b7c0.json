[{"id":0,"href":"/posts/learning_accidents/","title":"Praising learning accidents","section":"Blog","content":"I have always been an unremarkable football player. I occasionally joined some informal games in the breaks between classes. More when I was younger, and less often as I grew older. By middle school (grades 7-9) I barely played. I was much more successful at miniature sports: ping pong or table soccer.\nHowever I remember this one afternoon in 8th grade, when I joined a game by the insistence of my classmates. I thought it was all pretty unremarkable, until after the game, one of my friends came to me and praised my passing “technique”. He had noticed that I tended to kick the ball in an arc, lifted above the ground, when trying to pass to another teammate. And this, he said, made it hard for the other team to intercept.\nThe thing is, this was purely accidental. I was not trying to make tricky passes, so much as I was trying to get rid of the ball without stumbling on it. I was overloaded enough with the basics. But here was my friend, who played football competitively, praising my awkwardness as if it were a skill!\nIt made me wonder, could I actually be better at this than I thought? In the end, my “trick”, which I repeated a couple of times in future games (now consciously), was not enough to make me a good player. But I never forgot that comment! It is a memory I still hold dear.\nI was reminded of this experience when reading the colorful “Surely You\u0026rsquo;re Joking, Mr. Feynman!”. There’s a story surrounding Feynman’s experience of learning how to draw as an adult:\nJerry turned out to be a very good teacher. He told me first to go home and draw anything. So I tried to draw a shoe; then I tried to draw a flower in a pot. It was a mess! The next time we met I showed him my attempts: \u0026ldquo;Oh, look!\u0026rdquo; he said. \u0026ldquo;You see, around in back here, the line of the flower pot doesn\u0026rsquo;t touch the leaf.\u0026rdquo; (I had meant the line to come up to the leaf.) \u0026ldquo;That\u0026rsquo;s very good. It\u0026rsquo;s a way of showing depth. That\u0026rsquo;s very clever of you.\u0026rdquo;\n\u0026ldquo;And the fact that you don\u0026rsquo;t make all the lines the same thickness (which I didn\u0026rsquo;t mean to do) is good. A drawing with all the lines the same thickness is dull.\u0026rdquo; It continued like that: Everything that I thought was a mistake, he used to teach me something in a positive way. He never said it was wrong; he never put me down. So I kept on trying, and I gradually got a little bit better, but I was never satisfied.\nHere too, is a competent person praising the technique of an amateur, who is engaging with the task at a much lower level of competence and ambition. Neither I nor Feynman were foolish enough to believe these were more than “accidents”, and yet the mere fact that someone we respected praised them genuinely, turned out to be immensely rewarding (Feynman went out to become a much better drawer than I ever became a football player). These outcomes happened by chance, but they were also easy enough to repeat now that someone had brought our attention to it. So we could already do something interesting! And, in a sense, they were achieved for free. What other accidental techniques may we find next if we only keep practicing?\nThe most common strategy to teach animals how to perform complex tricks is called “shaping”. It boils down to rewarding spontaneous small actions that seem necessary to perform the trick as a whole. For instance, you can easily teach a chicken to press a lightbulb switch by rewarding it (giving it food) everytime it makes a step closer to the switch, and once it gets there reliably, everytime it pecks on the switch. In a matter of minutes, you can get the chicken to systematically move towards the switch and flip it on! This works with all sorts of animals\u0026hellip; and perhaps humans too.\nThe trainer must wait for the animal to act spontaneously and reward those actions that seem the most promising (or surprising). Because they come unforced, these actions have an interesting mix of individual proclivity and randomness. They could be the seeds of a unique personal technique later down the road.\n"},{"id":1,"href":"/posts/integration_differentiation/","title":"Derivatives, integrals, anti-derivatives and anti-integrals","section":"Blog","content":"import numpy as np import matplotlib.pyplot as plt import seaborn seaborn.set_style(\u0026#39;darkgrid\u0026#39;) seaborn.set(font_scale=1.2) def draw_arrows(ax, top_from, top_to, top_text_xy, bottom_from, bottom_to, bottom_text_xy, diff_top=True): text_top = \u0026#34;Differentiation\u0026#34; text_bottom = \u0026#34;Integration\u0026#34; if not diff_top: text_top, text_bottom = text_bottom, text_top ax.annotate( \u0026#34;\u0026#34;, top_from, top_to, xycoords=\u0026#34;axes fraction\u0026#34;, size=\u0026#34;large\u0026#34;, ha=\u0026#34;left\u0026#34;, va=\u0026#34;center\u0026#34;, arrowprops=dict( arrowstyle=\u0026#34;-\u0026gt;\u0026#34;, color=\u0026#34;k\u0026#34;, lw=2, connectionstyle=\u0026#34;angle3,angleA=50,angleB=-50\u0026#34;, ), ) ax.text(*top_text_xy, text_top, transform=ax.transAxes, ha=\u0026#34;center\u0026#34;) ax.annotate( \u0026#34;\u0026#34;, bottom_from, bottom_to, xycoords=\u0026#34;axes fraction\u0026#34;, size=\u0026#34;large\u0026#34;, ha=\u0026#34;left\u0026#34;, va=\u0026#34;center\u0026#34;, arrowprops=dict( arrowstyle=\u0026#34;-\u0026gt;\u0026#34;, color=\u0026#34;k\u0026#34;, lw=2, connectionstyle=\u0026#34;angle3,angleA=50,angleB=-50\u0026#34;, ), ) ax.text(*bottom_text_xy, text_bottom, transform=ax.transAxes, ha=\u0026#34;center\u0026#34;) def draw_deltas(ax, dx_from, dx_to, dx_width, dy_from, dy_to, dy_width, y_is_delta=True): ax.annotate( \u0026#34;$\\Delta x$\u0026#34;, dx_from, dx_to, size=\u0026#34;large\u0026#34;, ha=\u0026#34;center\u0026#34;, va=\u0026#34;center\u0026#34;, arrowprops=dict(arrowstyle=f\u0026#34;-[, widthB={dx_width}\u0026#34;, color=\u0026#34;k\u0026#34;,), ) ax.annotate( \u0026#34;$\\Delta y$\u0026#34; if y_is_delta else \u0026#34;$y$\u0026#34;, dy_from, dy_to, size=\u0026#34;large\u0026#34;, ha=\u0026#34;left\u0026#34;, va=\u0026#34;center\u0026#34;, arrowprops=dict(arrowstyle=f\u0026#34;-[, widthB={dy_width}\u0026#34;, color=\u0026#34;k\u0026#34;), ) \\(\\) There are two ways of describing a sequence of (\\(x\\), \\(y\\)) points:\nEnumerate all (\\(x\\), \\(y\\)) pairs Specify the first (\\(x_0\\), \\(y_0\\)) pair and the distance (\\(\\Delta x\\), \\(\\Delta y\\)) of each subsequent point In a loose sense, differentiation goes from 1. to 2., and integration goes from 2. to 1.\nf = lambda x: x ** 2 df = lambda x: 2 * x dx = 0.2 x = np.arange(0, 4+dx, dx) y = f(x) focus = np.array([1, 5, 10, 15]) fig, axes = plt.subplots(1, 3, figsize=(14, 4)) fig.subplots_adjust(wspace=0.3) ax = axes[0] ax.scatter(x, y, color=\u0026#34;k\u0026#34;) ax.text(3.5-0.2, f(3.5), \u0026#34;$y = x^2$\u0026#34;, va=\u0026#34;bottom\u0026#34;, ha=\u0026#34;right\u0026#34;) ax.set_ylabel(\u0026#34;y\u0026#34;) ax = axes[1] ax.scatter(x, y, color=\u0026#34;k\u0026#34;) ax.scatter(x[0], y[0], color=\u0026#34;C2\u0026#34;) ax.scatter(x[focus], y[focus], color=\u0026#34;C1\u0026#34;) ax.vlines(x[1:], y[:-1], y[1:], color=\u0026#34;k\u0026#34;) ax.annotate( \u0026#34;$(x_0, y_0)$\u0026#34;, (0.05, -0.05), (.1, 3.3), size=\u0026#34;large\u0026#34;, ha=\u0026#34;left\u0026#34;, va=\u0026#34;center\u0026#34;, arrowprops=dict(arrowstyle=\u0026#34;-\u0026gt;\u0026#34;, color=\u0026#34;k\u0026#34;), ) ax.set_ylabel(\u0026#34;y\u0026#34;) mid = (f(3-dx) + f(3)) / 2 draw_deltas( ax, (3 + dx/2, 7.5), (3 + dx/2, 6), 0.3, (3 + dx*2, mid), (3 + 0.6, mid), 0.4 ) ax = axes[2] ax.scatter(x[1:], df(x)[1:] * dx, color=\u0026#34;k\u0026#34;) ax.scatter(x[focus], df(x)[1:][focus-1] * dx, color=\u0026#34;C1\u0026#34;) ax.vlines(x[1:], 0, df(x)[1:] * dx, color=\u0026#34;k\u0026#34;) ax.text(3.5-0.1, df(3.5) * dx, \u0026#34;$\\Delta y = 2x \\Delta x$\u0026#34;, va=\u0026#34;bottom\u0026#34;, ha=\u0026#34;right\u0026#34;) ax.set_ylabel(\u0026#34;$\\Delta y$\u0026#34;) draw_arrows( ax, (0.35, 0.85), (-0.65, 0.85), (-0.15, 1.2), (-0.65, -0.1), (0.35, -0.1), (-0.15, -.3), ) for ax in axes: ax.set_xlabel(\u0026#34;x\u0026#34;) Actually when we differentiate, we rather store the ratio of \\(\\frac{\\Delta y}{\\Delta x}\\), which is also the slope of the straigth line that connects \\((x_i, y_i)\\) to \\((x_{i+1}, y_{i+1})\\)\nfig, ax = plt.subplots(figsize=(4.5/1.2,6/1.2)) ax.scatter([0, 1], [0, 2], c=\u0026#34;k\u0026#34;) ax.plot([-0.1, 1.1], [-0.2, 2.2], c=\u0026#34;C1\u0026#34;) plt.text( 0.25, 1.15, \u0026#34;$\\\\frac{y_{i+1} - y_i}{x_{i+1} - x_i} = \\\\frac{\\Delta y}{\\Delta x} = 2$\u0026#34;, ha=\u0026#34;center\u0026#34;, va=\u0026#34;center\u0026#34;, fontsize=20, rotation=60.5, ) ax.annotate( \u0026#34;$\\Delta x$\u0026#34;, (0.5, -0.5), (0.5, -0.75), size=\u0026#34;large\u0026#34;, ha=\u0026#34;center\u0026#34;, va=\u0026#34;center\u0026#34;, arrowprops=dict(arrowstyle=\u0026#34;-[, widthB=2.7\u0026#34;, color=\u0026#34;k\u0026#34;,), ) ax.set_ylim([-1, 2.5]) ax.set_xlim([-0.5, 1.75]) ax.annotate( \u0026#34;$\\Delta y$\u0026#34;, (1.25, 1.0), (1.5, 1.0), size=\u0026#34;large\u0026#34;, ha=\u0026#34;left\u0026#34;, va=\u0026#34;center\u0026#34;, arrowprops=dict(arrowstyle=\u0026#34;-[, widthB=4.6\u0026#34;, color=\u0026#34;k\u0026#34;), ) ax.set_xticks([0, 0.5, 1, 1.5]) ax.set_yticks([0, 1, 2]); This makes it so that the output of differentation is mostly the same regardless of the density of points in the original curve\ndx1 = 0.1 x1 = np.arange(0, 4+dx1, dx1) dx2 = 0.25 x2 = np.arange(0, 4+dx2, dx2) fig, axes = plt.subplots(1, 3, figsize=(12, 4)) ax = axes[0] ax.scatter(x1, f(x1), color=\u0026#34;k\u0026#34;, alpha=0.7, s=14, label=f\u0026#34;$\\Delta x = {dx1}$\u0026#34;) ax.scatter(x2, f(x2), color=\u0026#34;C1\u0026#34;, alpha=0.7, s=14, label=f\u0026#34;$\\Delta x = {dx2}$\u0026#34;) ax.legend() ax.set_ylabel(\u0026#34;y\u0026#34;) ax.set_xlabel(\u0026#34;x\u0026#34;) ax = axes[1] ax.scatter(x1[1:], np.diff(f(x1)), color=\u0026#34;k\u0026#34;, alpha=0.7, s=14) ax.scatter(x2[1:], np.diff(f(x2)), color=\u0026#34;C1\u0026#34;, alpha=0.7, s=14) ax.set_ylabel(\u0026#34;$\\Delta y$\u0026#34;) ax.set_xlabel(\u0026#34;x\u0026#34;) ax = axes[2] ax.scatter(x1[1:], np.diff(f(x1)) / dx1, color=\u0026#34;k\u0026#34;, alpha=0.7, s=14) ax.scatter(x2[1:], np.diff(f(x2)) / dx2, color=\u0026#34;C1\u0026#34;, alpha=0.7, s=14) ax.set_ylabel(\u0026#34;$\\\\frac{\\Delta y}{\\Delta x}$\u0026#34;) ax.set_xlabel(\u0026#34;x\u0026#34;) fig.tight_layout(); Integration as the inverse of differentation # Once we have a set of differences (or difference ratios), we can restore the original curve by adding those differences, starting from the initial point \\((x0, y0)\\)\n\\[y_i = y_0 + \\sum_0^x{\\Delta y_i} = y_0 + \\sum_0^x{\\frac{\\Delta y_i}{\\Delta x}}\\Delta x\\]\nfig, axes = plt.subplots(1, 3, figsize=(12, 4)) ax = axes[0] ax.scatter(x1[1:], np.diff(f(x1)) / dx1, color=\u0026#34;k\u0026#34;, alpha=0.7, s=14, label=f\u0026#34;$\\Delta x = {dx1}$\u0026#34;) ax.scatter(x2[1:], np.diff(f(x2)) / dx2, color=\u0026#34;C1\u0026#34;, alpha=0.7, s=14, label=f\u0026#34;$\\Delta x = {dx2}$\u0026#34;) ax.legend(); ax.set_ylabel(\u0026#34;$\\\\frac{\\Delta y}{\\Delta x}$\u0026#34;) ax = axes[1] ax.scatter(x1, np.cumsum(np.diff(f(x1), prepend=x1[0]) / dx1), color=\u0026#34;k\u0026#34;, alpha=0.7, s=14) ax.scatter(x2, np.cumsum(np.diff(f(x2), prepend=x2[0]) / dx2), color=\u0026#34;C1\u0026#34;, alpha=0.7, s=14) ax = axes[1] ax.scatter(x1, np.cumsum(np.diff(f(x1), prepend=x1[0]) / dx1), color=\u0026#34;k\u0026#34;, alpha=0.7, s=14) ax.scatter(x2, np.cumsum(np.diff(f(x2), prepend=x2[0]) / dx2), color=\u0026#34;C1\u0026#34;, alpha=0.7, s=14) ax.set_ylabel(\u0026#34;$y_0 + \\sum_0^x{\\\\frac{\\Delta y}{\\Delta x}}$\u0026#34;) ax = axes[2] ax.scatter(x1, np.cumsum(np.diff(f(x1), prepend=x1[0]) / dx1) * dx1, color=\u0026#34;k\u0026#34;, alpha=0.7, s=14) ax.scatter(x2, np.cumsum(np.diff(f(x2), prepend=x2[0]) / dx2) * dx2, color=\u0026#34;C1\u0026#34;, alpha=0.7, s=14) ax.set_ylabel(\u0026#34;$y_0 + \\sum_0^x{\\\\frac{\\Delta y}{\\Delta x}\\Delta x} = y_0 + \\sum_0^x{\\Delta y}$\u0026#34;) for ax in axes: ax.set_xlabel(\u0026#34;x\u0026#34;) fig.tight_layout(); In that sense integration is the inverse of differentation in the same sense that addition and multiplication are the inverses of subtraction and division.\nIf we add up (integrate) all the differences from a starting point, we get back the original series.\nBut this process of integration has another interesting meaning\u0026hellip;\nDifferentiation as the inverse of integration # Let\u0026rsquo;s grab the leftmost plot from above and forget that it describes \\(\\frac{\\Delta y}{\\Delta x}\\).\nLet\u0026rsquo;s say we have just a vanilla \\(y = 2x\\) series.\nWhat are we doing when we add up all the \\(y\\) up to \\(x\\) and multiply by \\(\\Delta x\\)?\n\\[s_i = \\sum_0^x{y \\Delta x}\\]\ng = lambda x : 2*x sg = lambda x : x ** 2 dx = 0.25 x = np.arange(0, 3.5+dx, dx) y = g(x) focus = 9 fig, axes = plt.subplots(1, 3, figsize=(14, 4)) fig.subplots_adjust(wspace=0.3) ax = axes[0] ax.scatter(x, y, color=\u0026#34;k\u0026#34;) ax.text(3.2-0.2, g(3.2), \u0026#34;$y = 2x$\u0026#34;, va=\u0026#34;bottom\u0026#34;, ha=\u0026#34;right\u0026#34;) ax.set_ylabel(\u0026#34;y\u0026#34;) ax = axes[1] ax.scatter(x[focus:], y[focus:], color=\u0026#34;k\u0026#34;) ax.scatter(x[:focus], y[:focus], color=\u0026#34;C1\u0026#34;) ax.scatter(x[focus], y[focus], color=\u0026#34;C0\u0026#34;) ax.vlines(x[:focus], 0, y[:focus], color=\u0026#34;C1\u0026#34;) ax.fill_between(x[:focus+1], 0, y[:focus+1], step=\u0026#34;post\u0026#34;, color=\u0026#34;C1\u0026#34;, alpha=0.7) ax.bar(x[focus]+dx/2, y[focus], width=dx, color=\u0026#34;C0\u0026#34;, alpha=0.7, ec=\u0026#34;C0\u0026#34;) ax.set_ylabel(\u0026#34;y\u0026#34;) ax.set_ylim([-.5, None]) mid = y[focus] / 2 draw_deltas( ax, (x[focus] + dx/2, y[focus] + 1.0), (x[focus] + dx/2, y[focus] + 1.8), 0.4, (x[focus] + dx + 0.15, mid), (x[focus] + dx + 0.4, mid), 3.58, y_is_delta=False, ) ax = axes[2] ax.scatter(x, sg(x), color=\u0026#34;k\u0026#34;) ax.scatter(x[focus-1], sg(x[focus-1]), color=\u0026#34;C1\u0026#34;) ax.scatter(x[focus], sg(x[focus]), color=\u0026#34;C0\u0026#34;) ax.vlines(x[focus], sg(x[focus-1]), sg(x[focus]), color=\u0026#34;C0\u0026#34;) ax.text(3.1 - 0.2, sg(3.1), \u0026#34;$s \\\\approx x^2$\u0026#34;, ha=\u0026#34;right\u0026#34;) ax.set_ylabel(\u0026#34;$s = \\sum_0^x{\\ y \\Delta x}$\u0026#34;, labelpad=-5) draw_arrows( ax, (0.35-0.2, 0.85), (-0.65-0.2, 0.85), (-0.15, 1.2), (-0.65, -0.1), (0.35, -0.1), (-0.15, -.3), diff_top=False, ) for ax in axes: ax.set_xlabel(\u0026#34;x\u0026#34;) We are adding up the areas of the rectangles below \\(y\\) up to \\(x\\)! So our function \\(s\\) is an area function!\nNow, the difference between successive points in that area function \\(\\Delta s_i\\) gives us the difference in areas up to \\(x_{i}\\) and up to \\(x_{i-1}\\), which must intuitively be \\(y_i\\Delta x\\) and the ratio \\(\\frac{y_i \\Delta x}{\\Delta x} = y_i\\)\nThis is just another way of saying that differentation is the inverse of integration.\nBonus: Illustrating the sin function # f = lambda x: np.sin(x) df = lambda x: np.cos(x) dx = 0.3 x = np.arange(0, np.pi*2+dx, dx) y = f(x) focus = np.array([1, 6, 11, 16]) fig, axes = plt.subplots(1, 3, figsize=(14, 4)) fig.subplots_adjust(wspace=0.3) ax = axes[0] ax.scatter(x, y, color=\u0026#34;k\u0026#34;) ax.text(6, 0.5, \u0026#34;$y = sin(x)$\u0026#34;, va=\u0026#34;bottom\u0026#34;, ha=\u0026#34;right\u0026#34;) ax.set_ylabel(\u0026#34;y\u0026#34;) ax = axes[1] ax.scatter(x, y, color=\u0026#34;k\u0026#34;) ax.scatter(x[0], y[0], color=\u0026#34;C2\u0026#34;) ax.scatter(x[focus], y[focus], color=\u0026#34;C1\u0026#34;) ax.vlines(x[1:], y[:-1], y[1:], color=\u0026#34;k\u0026#34;) ax.annotate( \u0026#34;$(x_0, y_0)$\u0026#34;, (0.05, -0.05), (.1, -.3), size=\u0026#34;large\u0026#34;, ha=\u0026#34;left\u0026#34;, va=\u0026#34;center\u0026#34;, arrowprops=dict(arrowstyle=\u0026#34;-\u0026gt;\u0026#34;, color=\u0026#34;k\u0026#34;), ) draw_deltas( ax, (3.2, 0.52), (3.2, 0.75), .25, (3.7, 0.27), (4.05, 0.27), .85, ) ax.set_ylabel(\u0026#34;y\u0026#34;) ax = axes[2] ax.scatter(x[1:], np.diff(y), color=\u0026#34;k\u0026#34;) ax.scatter(x[focus], np.diff(y)[focus-1], color=\u0026#34;C1\u0026#34;) ax.vlines(x[1:], 0, np.diff(y), color=\u0026#34;k\u0026#34;) ax.text(5.25, 0.2, \u0026#34;$\\Delta y \\\\approx cos(x) \\Delta x$\u0026#34;, va=\u0026#34;bottom\u0026#34;, ha=\u0026#34;right\u0026#34;) ax.set_ylabel(\u0026#34;$\\Delta y$\u0026#34;) draw_arrows( ax, (0.35, 0.85), (-0.65, 0.85), (-0.15, 1.2), (-1.0, 0.22), (0.15, 0.22), (-0.35, -.21), ) for ax in axes: ax.set_xlabel(\u0026#34;x\u0026#34;); g = lambda x : np.cos(x) sg = lambda x : np.sin(x) dx = 0.25 x = np.arange(0, np.pi*2+dx, dx) y = g(x) focus = 9 fig, axes = plt.subplots(1, 3, figsize=(14, 4)) fig.subplots_adjust(wspace=0.35) ax = axes[0] ax.scatter(x, y, color=\u0026#34;k\u0026#34;) ax.text(5.3, 0.75, \u0026#34;$y = cos(x)$\u0026#34;, va=\u0026#34;bottom\u0026#34;, ha=\u0026#34;right\u0026#34;) ax.set_ylabel(\u0026#34;y\u0026#34;) ax = axes[1] ax.scatter(x[focus:], y[focus:], color=\u0026#34;k\u0026#34;) ax.scatter(x[:focus], y[:focus], color=\u0026#34;C1\u0026#34;) ax.scatter(x[focus], y[focus], color=\u0026#34;C0\u0026#34;) ax.vlines(x[:focus], 0, y[:focus], color=\u0026#34;C1\u0026#34;) ax.fill_between(x[:focus+1], 0, y[:focus+1], step=\u0026#34;post\u0026#34;, color=\u0026#34;C1\u0026#34;, alpha=0.7) ax.bar(x[focus]+dx/2, y[focus], width=dx, color=\u0026#34;C0\u0026#34;, alpha=0.7, ec=\u0026#34;C0\u0026#34;) ax.set_ylabel(\u0026#34;y\u0026#34;) # ax.set_ylim([-.5, None]) mid = y[focus] / 2 draw_deltas( ax, (x[focus] + dx/2, 0.1), (x[focus] + dx/2, .3), 0.3, (x[focus] + dx + 0.3, mid), (x[focus] + dx + 0.65, mid), 1.78, y_is_delta=False, ) ax = axes[2] ax.scatter(x, sg(x), color=\u0026#34;k\u0026#34;) ax.scatter(x[10], sg(x[10]), color=\u0026#34;C1\u0026#34;) ax.scatter(x[11], sg(x[11]), color=\u0026#34;C0\u0026#34;) ax.vlines(x[11], sg(x[10]), sg(x[11]), color=\u0026#34;C0\u0026#34;) ax.text(6.5 - 0.1, sg(6.5)+ 0.3, \u0026#34;$s \\\\approx sin(x)$\u0026#34;, ha=\u0026#34;right\u0026#34;) ax.set_ylabel(\u0026#34;$s = \\sum_0^x{\\ y \\Delta x}$\u0026#34;, labelpad=-5) draw_arrows( ax, (0.35-0.25, 0.85), (-0.65-0.25, 0.85), (-0.35, 1.2), (-0.65, .1), (0.35, 0.1), (-0.15, -.3), diff_top=False, ) for ax in axes: ax.set_xlabel(\u0026#34;x\u0026#34;) "},{"id":2,"href":"/posts/smc_basic_algorithm/","title":"A simple Sequential Monte Carlo algorithm for posterior approximation","section":"Blog","content":" Introduction # Sequential Monte Carlo (SMC) can be used to take samples from posterior distributions, as an alternative to popular methods such as Markov Chain Monte Carlo (MCMC) like Metropolis-Hastings, Gibbs Sampling or more state-of-the-art Hamiltonian Monte Carlo (HMC) and No-U-Turn Sampler (NUTS).\nInstead of creating a single Markov Chain, SMC works by keeping track of a large population of samples, which, in a similar spirit to Genetic Algorithms can be \u0026ldquo;selected\u0026rdquo; and \u0026ldquo;mutated\u0026rdquo; to evolve a better \u0026ldquo;fit\u0026rdquo; to the posterior distribution.\nExperience suggests SMC is particularly well fit to the following settings:\nMulti-modal posterior distributions Online inference when data accumulates over time Approximate Bayesian Inference when the likelihood function cannot be easily written down In this article I introduce the basic components that make up a simple SMC algorithm. In future articles, I present more complex variations that build up towards the specific algorithm that is employed in the PyMC3 library.\nToy 2D Gaussian example # As with MCMC, SMC approximates the posterior distribution via careful weighted sampling. However, while MCMC approximates a distribution through a single random walk that unrolls over time, SMC does this in a parallel manner. At each step, it keeps track of a series of samples (also known as particles) that approximate the distribution as a whole.\nThis picture tries to illustrate this distinction for a simple 2D Gaussian posterior that will be used throughout this article:\n\\(\\) \\[ \\text{pdf}(x, y) = \\text{exp}(-\\begin{bmatrix}x\\\\ y\\end{bmatrix}^T \\begin{bmatrix}1\u0026amp;0.5\\\\ 0.5\u0026amp;1\\end{bmatrix}^{-1} \\begin{bmatrix}x\\\\ y\\end{bmatrix}) \\]\nApproximation to the 2D Gaussian posterior shown on the left plot. The middle plot shows the approximation from a single MCMC chain, with the samples connected sequentially, emphasizing the autocorrelated random walk behavior. The right plot shows the approximation from the SMC algorithm, where each sample is independent from the rest.\nWhy are we even doing this?\nThe example above with a 2D Gaussian is deceptively simple and there is no reason why we would need to use Monte Carlo approximations (be it MCMC or SMC) to understand it. Usually in the context of Bayesian data analysis we are working with a model that describes a complicated and highly dimensional posterior distribution that cannot be written down mathematically (or as mathematicians prefer, analytically).\nIn addition, even if the posterior distribution could be described mathematically, it is often very difficult to work with. We are usually interested in chopping the posterior distribution into a smaller number of components that we care about (marginalization) or summarizing it into metrics that are understandable such as correlations, averages and standard deviations (expectations). Surprisingly, these sort of operations are trivial if we can get a hold of a representative set of samples from the distribution in question. All we need is to do some smart indexing and call functions such as numpy.mean() and numpy.std()!\nThe core of the SMC algorithm is very simple:\nWe start by creating a large population of particles, usually by sampling from the prior distribution. We then compute a weight for each particle, which is proportional to the posterior probability at that \u0026ldquo;point\u0026rdquo;. These weights are used to sample, with replacement, a new population of particles. This will lead to a population that is more representative of the posterior distribution. On average, a particle that is 3x more probable than another will be resampled 3x as often. Finally, we introduce some \u0026ldquo;mutations\u0026rdquo; in the population. This could be as simple as adding a random uniform jittering to each particle dimension, but, we can also try to \u0026ldquo;guide\u0026rdquo; the particles in a more clever way towards areas of larger posterior mass. The pseudocode for the SMC algorithm is given below:\n# hyperparameters n_particles = 2000 n_steps = 10 # initialize population of particles from prior particles = sample_prior(n_particles) # main loop for step in range(n_steps): # compute particle weights in proportion # to the posterior distribution probability weights = compute_weights(particles, posterior) # resample particles (with replacement) # based on their weights particles = resample(particles, weights) # mutate particles to reintroduce variation # and better explore the posterior distribution particles = mutate(particles) # final approximation is given by the final particles posterior = particles Let\u0026rsquo;s flesh out these steps in detail.\nA particle is born # What is a particle?\nA particle (or a sample in conventional MCMC) is a numerical vector with one entry for each parameter in the posterior function that we are interested in. In the 2D Gaussian example above it was a 2D-vector with {x, y} coordinates.\nparticle = {\u0026quot;x\u0026quot;: -0.5, \u0026quot;y\u0026quot;: 0.2} In a simple linear regression model it might be an \\(N^D\\)-vector containing a value for the intercept, a coefficient for each predictor in our dataset and a noise term for the observations.\nparticle = {\u0026quot;intercept\u0026quot;: 1.0, \u0026quot;coef_1\u0026quot;: 0.5, \u0026quot;coef_2\u0026quot;: 0.2, \u0026quot;noise\u0026quot;: 3.0} import numpy as np import scipy.stats as st import matplotlib.pyplot as plt import seaborn as sns sns.set_style(\u0026#34;dark\u0026#34;) sns.set(font_scale = 1.4) def create_plot(rows=1, cols=1): fig, ax = plt.subplots(rows, cols, figsize=(6*cols, 6*rows), sharex=True, sharey=True) # single plot if rows + cols == 2: ax.set_aspect(\u0026#39;equal\u0026#39;, \u0026#39;box\u0026#39;) ax.set_xticks([]) ax.set_yticks([]) # multiple plot else: for axi in ax.ravel(): axi.set_aspect(\u0026#39;equal\u0026#39;, \u0026#39;box\u0026#39;) axi.set_xticks([]) axi.set_yticks([]) return fig, ax def make_arrow(a, b, axA, axB): from matplotlib.patches import ConnectionPatch return ConnectionPatch( a, b, coordsA=\u0026#34;axes fraction\u0026#34;, coordsB=\u0026#34;axes fraction\u0026#34;, axesA=axA, axesB=axB, color=\u0026#34;k\u0026#34;, fc=\u0026#34;k\u0026#34;, arrowstyle=\u0026#34;-|\u0026gt;\u0026#34;, mutation_scale=30, lw=2, zorder=10, ) Let\u0026rsquo;s create our very first particles:\nclass Particle: def __init__(self, x, y): self.x = x self.y = y adam, eve = Particle(x=1, y=0), Particle(x=0, y=1) _, ax = create_plot() ax.scatter(adam.x, adam.y) ax.annotate(\u0026#34;Adam\u0026#34;, (adam.x, adam.y+.1), ha=\u0026#34;center\u0026#34;, fontsize=16) ax.scatter(eve.x, eve.y) ax.annotate(\u0026#34;Eve\u0026#34;, (eve.x, eve.y+.1), ha=\u0026#34;center\u0026#34;, fontsize=16) ax.set_xlim([-0.5, 1.5]) ax.set_ylim([-0.5, 1.5]); Kidding aside, we need to get a whole population of particles. How should we choose?\nMaking the effort to pick a good initial population can be very useful. Remember that the goal is to obtain a representative sample from the posterior distribution, and so the closer our initial population is to the posterior, the closer we are to being done.\nRegardless, and to keep things simple with our toy example, we will just take a random sample from the uniform grid:\ndef sample_uniform_grid(min_x, max_x, min_y, max_y, n): particles = [] for i in range(n): x = np.random.uniform(min_x, max_x) y = np.random.uniform(min_y, max_y) particle = Particle(x=x, y=y) particles.append(particle) return particles particles = sample_uniform_grid(-3, 3, -3, 3, n=1000) xs = [particle.x for particle in particles] ys = [particle.y for particle in particles] _, ax = create_plot() ax.scatter(xs, ys, alpha=0.3) ax.set_title(\u0026#34;The prior population\u0026#34;); Picking favorites # Now that we have a population of particles, it\u0026rsquo;s time to evolve it into a proper approximation of the posterior distribution! To do this, we weight each particle by its posterior probability, normalize all the population weights so that they add up to 1.0 and use them to resample with replacement.\ndef posterior(particle): \u0026#34;\u0026#34;\u0026#34; Unnormalized 2D Gaussian with [0, 0] mean and [[0.5, 1.0], [1.0, 0.5]] covariance matrix \u0026#34;\u0026#34;\u0026#34; xy = np.array([particle.x, particle.y]) cov = np.array([[1.0, 0.5], [0.5, 1.0]]) return np.exp(-(xy) @ np.linalg.inv(cov) @ (xy)) def compute_weights(particles, posterior): weights = np.array([posterior(particle) for particle in particles]) weights /= np.sum(weights) # normalize weights return weights def resample(particles, weights): idxs = np.arange(len(particles)) sampled_idxs = np.random.choice(idxs, p=weights, replace=True, size=len(particles)) resampled_particles = [] for idx in sampled_idxs: resampled_particles.append(particles[idx]) return resampled_particles _, ax = create_plot(1, 3) xs = [particle.x for particle in particles] ys = [particle.y for particle in particles] ax[0].scatter(xs, ys, alpha=0.2) ax[0].set_title(\u0026#34;Initial particles\u0026#34;) weights = compute_weights(particles, posterior) rescaled_weights = 0.95 * (weights - np.min(weights)) / (np.max(weights) - np.min(weights)) + 0.05 ax[1].scatter(xs, ys, s=150 * rescaled_weights, alpha=0.2, color=\u0026#34;C3\u0026#34;) ax[1].set_title(\u0026#34;Particle weights\u0026#34;) resampled_particles = resample(particles, weights) xs = [particle.x for particle in resampled_particles] ys = [particle.y for particle in resampled_particles] ax[2].scatter(xs, ys, s=50, alpha=0.2) ax[2].set_title(\u0026#34;Resampled particles\u0026#34;) ax[1].add_artist(make_arrow((0.85, 0.5), (0.15, 0.5), ax[0], ax[1])); ax[2].add_artist(make_arrow((0.85, 0.5), (0.15, 0.5), ax[1], ax[2])); The initial population of particles is shown on the left plot. In the middle plot each particle is given a weight proportional to its posterior probability. The weights are illustrated by the particle size. In the right plot, the particles were resampled with replacement based on their weights. Each particle is plotted with the same transparency, and those resampled multiple times appear to be darker.\nIntroducing variation # The example above was a favorable one, where the initial population of particles happened to cover the bulk of the posterior distribution. We may not always be this lucky, for instance when working with very complex distributions or when our choice for initial population of particles is not great, as in the exaggerated example below:\n_, ax = create_plot(1, 3) ax[0].set_xlim([-3, 3]) ax[0].set_ylim([-3, 3]) bad_particles = sample_uniform_grid(-3, 0, -3, 0, 500) xs = [particle.x for particle in bad_particles] ys = [particle.y for particle in bad_particles] ax[0].scatter(xs, ys, alpha=0.2) ax[0].set_title(\u0026#34;Initial particles\u0026#34;) weights = compute_weights(bad_particles, posterior) rescaled_weights = 0.95 * (weights - np.min(weights)) / (np.max(weights) - np.min(weights)) + 0.05 ax[1].scatter(xs, ys, s=150 * rescaled_weights, alpha=0.2, color=\u0026#34;C3\u0026#34;) ax[1].set_title(\u0026#34;Particle weights\u0026#34;) bad_resampled_particles = resample(bad_particles, weights) xs = [particle.x for particle in bad_resampled_particles] ys = [particle.y for particle in bad_resampled_particles] ax[2].scatter(xs, ys, s=50, alpha=0.2) ax[2].set_title(\u0026#34;Resampled particles\u0026#34;) ax[1].add_artist(make_arrow((0.85, 0.5), (0.15, 0.5), ax[0], ax[1])); ax[2].add_artist(make_arrow((0.85, 0.5), (0.15, 0.5), ax[1], ax[2])); To obtain a robust algorithm we need some way for the population to \u0026ldquo;evolve\u0026rdquo; towards the target distribution. This is achieved by mutating the particles.\nThe mutation step is also important for reintroducing variability after the resampling step. Because resampled particles are exact copies of each other, if we were to rerun the weighting and resampling steps several times, the population would quickly converge to a singular particle.\nBlind evolution # The simplest mutation strategy is to add a random offset to each particle parameter:\ndef random_mutation(particles): new_particles = [] for particle in particles: # Add Gaussian noise around each particle dimension new_x = particle.x + np.random.normal(0, .2) new_y = particle.y + np.random.normal(0, .2) new_particle = Particle(x=new_x, y=new_y) new_particles.append(new_particle) return new_particles _, ax = create_plot(1, 4) ax[0].set_xlim([-3, 3]) ax[0].set_ylim([-3, 3]) particles = bad_resampled_particles xs = [particle.x for particle in particles] ys = [particle.y for particle in particles] ax[0].scatter(xs, ys, alpha=0.2) ax[0].set_title(\u0026#34;Resampled particles\u0026#34;) particles = random_mutation(particles) new_xs = [particle.x for particle in particles] new_ys = [particle.y for particle in particles] ax[1].scatter(new_xs, new_ys, alpha=0.2) ax[1].set_title(\u0026#34;Mutated particles\u0026#34;) weights = compute_weights(particles, posterior) particles = resample(particles, weights) xs = [particle.x for particle in particles] ys = [particle.y for particle in particles] ax[2].scatter(xs, ys, alpha=0.2) ax[2].set_title(\u0026#34;Resampled particles\u0026#34;) particles = random_mutation(particles) new_xs = [particle.x for particle in particles] new_ys = [particle.y for particle in particles] ax[3].scatter(new_xs, new_ys, alpha=0.2) ax[3].set_title(\u0026#34;Mutated particles\u0026#34;) ax[1].add_artist(make_arrow((0.85, 0.5), (0.15, 0.5), ax[0], ax[1])); ax[2].add_artist(make_arrow((0.85, 0.5), (0.15, 0.5), ax[1], ax[2])); ax[3].add_artist(make_arrow((0.85, 0.5), (0.15, 0.5), ax[2], ax[3])); Intelligent design # Creationists might have gotten it wrong when it comes to natural selection, but their premise makes a lot of sense: It would all have been much easier if someone had taken the driving seat. Fortunately that is something we can do in SMC, and in particular when it comes to how we mutate the population of particles.\nInstead of using a blind form of \u0026ldquo;mutation\u0026rdquo; as above, we can intelligently drive the particles towards areas of high probability in the posterior distribution. One way of doing this is to run each particle through a traditional MCMC algorithm for a specific number of steps and take the final position as the new mutated particle.\ndef metropolis_hastings_mutation(particles): # This should be parallelized new_particles = [] for particle in particles: new_particle = single_particle_mh(particle, steps=10) new_particles.append(new_particle) return new_particles def single_particle_mh(particle, steps): \u0026#34;\u0026#34;\u0026#34; Run a small Metropolis-Hastings MCMC chain around a single particle \u0026#34;\u0026#34;\u0026#34; # The proposal distribution should be tuned proposal_distribution = st.norm(0, .2) for step in range(steps): x_offset, y_offset = proposal_distribution.rvs(2) new_particle = Particle( x=particle.x + x_offset, y=particle.y + y_offset, ) # Compute Metropolis-Hastings jump probability given the ratio # between current and proposed particle probability current_probability = posterior(particle) proposed_probability = posterior(new_particle) jump_probability = min(1, proposed_probability / current_probability) if jump_probability \u0026gt;= np.random.rand(): particle = new_particle else: particle = particle return particle _, ax = create_plot(1, 4) ax[0].set_xlim([-3, 3]) ax[0].set_ylim([-3, 3]) particles = bad_resampled_particles xs = [particle.x for particle in particles] ys = [particle.y for particle in particles] ax[0].scatter(xs, ys, alpha=0.2) ax[0].set_title(\u0026#34;Resampled particles\u0026#34;) particles = metropolis_hastings_mutation(particles) new_xs = [particle.x for particle in particles] new_ys = [particle.y for particle in particles] ax[1].scatter(new_xs, new_ys, alpha=0.2) ax[1].set_title(\u0026#34;Mutated particles\u0026#34;) weights = compute_weights(particles, posterior) particles = resample(particles, weights) xs = [particle.x for particle in particles] ys = [particle.y for particle in particles] ax[2].scatter(xs, ys, alpha=0.2) ax[2].set_title(\u0026#34;Resampled particles\u0026#34;) particles = random_mutation(particles) new_xs = [particle.x for particle in particles] new_ys = [particle.y for particle in particles] ax[3].scatter(new_xs, new_ys, alpha=0.2) ax[3].set_title(\u0026#34;Mutated particles\u0026#34;) ax[1].add_artist(make_arrow((0.85, 0.5), (0.15, 0.5), ax[0], ax[1])); ax[2].add_artist(make_arrow((0.85, 0.5), (0.15, 0.5), ax[1], ax[2])); ax[3].add_artist(make_arrow((0.85, 0.5), (0.15, 0.5), ax[2], ax[3])); The population progressed much faster towards the target distribution.\nSummary # To summarize, here is the basic SMC algorithm again:\n# hyperparameters n_particles = 2000 n_steps = 10 # initialize population of particles from prior particles = sample_prior(n_particles) # main loop for step in range(n_steps): # compute particle weights in proportion # to the posterior distribution probability weights = compute_weights(particles, posterior) # resample particles (with replacement) # based on their weights particles = resample(particles, weights) # mutate particles to reintroduce variation # and better explore the posterior distribution particles = mutate(particles) # final approximation is given by the final particles posterior = particles What about the prior? # You might have noticed a large repetition of the word \u0026ldquo;posterior\u0026rdquo;, and a strange absence of \u0026ldquo;prior\u0026rdquo;. To keep things simple I chose to work with an implicitly uniform prior which does not affect the posterior calculations. Indeed the two are needed for a complete Bayesian inference. And in fact there is something very interesting that can be done when combining the two into a general SMC algorithm. That\u0026rsquo;s the topic of the [next article]!\nnb2hugo raw_notebooks/smc_basic_algorithm.ipynb --site-dir . --section posts "},{"id":3,"href":"/posts/gamma_distribution/","title":"A most unprincipled derivation of the gamma distribution","section":"Blog","content":" Introduction # In this article I will derive the gamma distribution in a most unprincipled way.\nWhy? First, there are many good resources out there explaining how to derive the gamma distribution from first principles, usually involving these idealized things called poisson processes. These are great sources and I would definitely recommend them. This one by Aerin Kim is amazing.\nHowever, more often than not, people use gamma distributions in real world problems for much more mundane reasons: It\u0026rsquo;s a well behaved yet flexible positive continuous distribution.\nBy deriving a distribution from a purely utilitarian perspective, we might get a better intuition on how and when to use it. Besides, once you go through such exercise, continuous probability distributions may start to seem a bit less magical. They may even make sense!\n\\(\\) Continuous probability distributions are mathematical objects that can be fully characterized by a probability density function (pdf). This function computes the density probability of a random outcome \\(x\\) given a pre-specified set of parameters. It must respect two simple constraints:\nAlways return a non-negative density for every possible parameter and random outcome \\(x\\). The density of every possible outcome \\(x\\), given a fixed set of parameters, must integrate to 1. To compute the probability that an event \\(x\\) will fall in the range \\([a, b]\\), we integrate the pdf over that range. The second requirement is simply saying that if \\([a, b]\\) corresponds to the range of all possible values of \\(x\\), the probability obtained from integrating the pdf must be 1. This makes sense given the convention that an event with probability of 1 corresponds to an absolutely certain event.\nWarmup exercise: the uniform distribution # To warmup, it may help to start with what is perhaps the simplest continuous probability distribution: the uniform. This core of this distribution is the constant function\n\\[ uniform(x; lower, upper) = 1\\]\nimport numpy as np import scipy.special import scipy.integrate import matplotlib.pyplot as plt import seaborn seaborn.set_style(\u0026#39;darkgrid\u0026#39;) seaborn.set(font_scale=1.4) def uniform(x, lower, upper): return np.ones_like(x) def plot_uniform(f, x, lower, upper, ax, color, pdf=False): y = f(x, lower, upper) area_y = scipy.integrate.quad(f, lower, upper, args=(lower, upper))[0] ax.plot(x, y, color=color) ax.fill_between(x, y, color=color, alpha=.2) ax.text( 0.5, 0.5, f\u0026#39;area={area_y:.1f}\u0026#39;, transform=ax.transAxes, ha=\u0026#39;center\u0026#39;, va=\u0026#39;center\u0026#39; ) ax.set_xticks([lower, upper]) ax.set_xlabel(\u0026#39;x\u0026#39;) if not pdf: ax.set_title(f\u0026#39;$uniform(x; {lower}, {upper})$\u0026#39;) else: ax.set_title(f\u0026#39;$uniform_{{pdf}}(x; {lower}, {upper})$\u0026#39;) _, ax = plt.subplots(1, 3, figsize=(14, 3.5)) lower, upper = 0, 1 x = np.linspace(lower, upper) plot_uniform(uniform, x, lower, upper, ax=ax[0], color=\u0026#39;C0\u0026#39;) lower, upper = 0.5, 2.5 x = np.linspace(lower, upper) plot_uniform(uniform, x, lower, upper, ax=ax[1], color=\u0026#39;C1\u0026#39;) lower, upper = 2, 2.5 x = np.linspace(lower, upper) plot_uniform(uniform, x, lower, upper, ax=ax[2], color=\u0026#39;C2\u0026#39;) plt.tight_layout() This conforms to the first requirement from above: all densities for possible values of \\(x\\) evaluate to a non-negative number (in this case 1.0). However, the second requirement is not fulfilled. To achieve this, all we need to do is to divide our original expression by the total area\n\\[ \\begin{aligned} uniform_{pdf}(x; lower, upper) \u0026amp;= \\frac{1}{\\int_{lower}^{upper} 1 dx} \\\\ \u0026amp;= \\frac{1}{x|_{lower}^{upper}} \\\\ \u0026amp;= \\frac{1}{upper - lower} \\\\ \\end{aligned} \\]\nAnd now we have a proper uniform probability density function! It might seem like we cheated, but this is really all there is to it.\ndef uniform_pdf(x, lower, upper): return np.ones_like(x) / (upper - lower) _, ax = plt.subplots(1, 3, figsize=(14, 3.5)) lower, upper = 0, 1 x = np.linspace(lower, upper) plot_uniform(uniform_pdf, x, lower, upper, pdf=True, ax=ax[0], color=\u0026#39;C0\u0026#39;) lower, upper = 0.5, 2.5 x = np.linspace(lower, upper) plot_uniform(uniform_pdf, x, lower, upper, pdf=True, ax=ax[1], color=\u0026#39;C1\u0026#39;) lower, upper = 2, 2.5 x = np.linspace(lower, upper) plot_uniform(uniform_pdf, x, lower, upper, pdf=True, ax=ax[2], color=\u0026#39;C2\u0026#39;) plt.tight_layout() _, ax = plt.subplots(figsize=(6, 4)) for i, (lower, upper) in enumerate(zip((0, 0.5, 2), (1, 2.5, 2.5))): x = np.linspace(lower, upper) y = uniform_pdf(x, lower, upper) ax.plot(x, y, color=f\u0026#39;C{i}\u0026#39;, label=f\u0026#39;{lower=}, {upper=}\u0026#39;) ax.fill_between(x, y, color=f\u0026#39;C{i}\u0026#39;, alpha=.2) ax.set_xlabel(\u0026#39;x\u0026#39;) ax.set_title(\u0026#39;$uniform_{pdf}(x; lower, upper)$\u0026#39;) ax.legend(fontsize=14); Let\u0026rsquo;s now turn to the mightier gamma distribution.\nThe gamma distribution # The gamma distribution is based on this funny looking function, with two parameters:\n\\[ gamma(x; a) = x^{a-1}e^{-x} \\]\nWe will consider the cases where \\(x \u0026gt; 0\\) and \\(a \u0026gt; 0\\). As with the uniform, \\(x\\) represents the possible random outcomes, while \\(a\\), analogous to the \\(lower\\) and \\(upper\\), is a fixed parameter that characterizes its probability density. Unlike the uniform, this distribution is not bounded, it allows for infinitely large \\(x\\) outcomes.\nLooking at the expression, one can notice that the first part \\(x^{a-1}\\) will grow quickly as x goes to \\(\\infty\\), while the second part \\(e^{-x}\\) will decrease exponentially as \\(x\\) increases. By multiplying the two we will obtain a rising curve followed by a declining one, as the two terms change in relative importance. Here is an example with \\(a=4\\)\na = 4 x = np.linspace(0, 20, 100) _, ax = plt.subplots(1, 3, figsize=(14, 3.5)) y1 = x ** (a-1) ax[0].plot(x, y1, lw=3, color=\u0026#39;k\u0026#39;) ax[0].set_title(\u0026#39;$x^{3}$\u0026#39;) y2 = np.exp(-x) ax[1].plot(x, y2, lw=3, color=\u0026#39;k\u0026#39;) ax[1].set_title(\u0026#39;$e^{-x}$\u0026#39;) y3 = y1 * y2 ax[2].plot(x, y3, lw=3, color=\u0026#39;k\u0026#39;) ax[2].set_title(\u0026#39;$x^{3}e^{-x}$\u0026#39;) plt.tight_layout() Let\u0026rsquo;s turn it into a python function and see how the function changes with different \\(a\\).\ndef gamma(x, a): return x**(a-1)*np.exp(-x) def plot_gamma(f, x, a, ax, color, pdf=False): y = f(x, a) # Integrate area between 0 and +inf area_y = scipy.integrate.quad(f, 0, np.inf, args=(a,))[0] ax.plot(x, y, color=color) ax.fill_between(x, y, color=color, alpha=.2) ax.text(0.5, 0.5, f\u0026#39;area={area_y:.1f}\u0026#39;, transform=ax.transAxes, ha=\u0026#39;center\u0026#39;, va=\u0026#39;center\u0026#39;) ax.set_xlabel(\u0026#39;x\u0026#39;) if not pdf: ax.set_title(f\u0026#39;$gamma(x; {a})$\u0026#39;) else: ax.set_title(f\u0026#39;$gamma_{{pdf}}(x; {a})$\u0026#39;) _, ax = plt.subplots(1, 3, figsize=(14, 3.5)) x = np.linspace(0, 20, 1000) plot_gamma(gamma, x, 4, ax=ax[0], color=\u0026#39;C0\u0026#39;) plot_gamma(gamma, x, 6, ax=ax[1], color=\u0026#39;C1\u0026#39;) plot_gamma(gamma, x, 8, ax=ax[2], color=\u0026#39;C2\u0026#39;) plt.tight_layout() Okay, perhaps not the most amazing looking curve. But we are not looking for amazing, just nice! And there are a couple of nice things going on:\nThe function seems to be positive everywhere in the range \\(x \\subset [0, \\infty]\\) It looks like the graph does not blow up as \\(x\\) goes to \\(\\infty\\), even for larger \\(a\\) The \\(a\\) parameter seems to have a meaningful effect on the shape of the function. Points 1 and 2 are needed for defining an unbounded positive probability density function, while point 3 is nice for making it a useful distribution.\nIf you never heard about the gamma function, you might be surprised to find out that the areas for the three examples all evaluate to integer values (subject to float representation). Even more surprising is the fact that these values correspond to \\((a-1)!\\). And analogous to the factorial function, the area under this expression preserves a certain recursive form of \\(n! = n(n-1)!\\), for any positive numbers (while the factorial is only defined for integers). This surprising fact was discovered by Euler in 1730.\nnp.math.factorial(3), np.math.factorial(5), np.math.factorial(7) (6, 120, 5040) scipy.special.gamma(3.5+1), 3.5 * scipy.special.gamma(3.5) (11.63172839656745, 11.63172839656745) Finding the normalization constant # In order to obtain a valid density function, we must be able to scale this function so that it integrates to 1. In theory, all we need to do is divide the original expression by the total area, as we did for the uniform.\n\\[ gamma_{pdf}(x; a) = \\frac{x^{a-1}e^{-x}}{\\int_{0}^{\\infty}{x^{a-1} e^{-x} dx}} \\]\nHowever, unlike the uniform, there is no simple form for the integral in the denominator. That might be slightly annoying, but it\u0026rsquo;s not critical as long as we can compute it. In the code used to generate the plots above, I used a generic integration approximator, but, fortunately for us, some folks have found more reliable or accurate approximations that can be used to compute this integral (see the Wikipedia entries for Stirling\u0026rsquo;s and Lanczos\u0026rsquo;s approximations).\nFinally, just because we cannot simplify the denominator expression, it doesn\u0026rsquo;t mean we have to write it everywhere. Let\u0026rsquo;s do some mathematical refactoring by encapsulating the denominator inside a function. To keep it math-appropriate we will use a Greek letter for its name, although something more verbose such as total_area_gamma would work as well. To keep with the convention, we will give it the uppercase gamma symbol \\(\\Gamma\\):\n\\[ gamma_{pdf}(x; a) = \\frac{x^{a-1}e^{-x}}{\\Gamma(a)} \\]\nScipy provides an implementation of the gamma function via scipy.special.gamma. Time to plot our proper gamma density function:\ndef gamma_pdf(x, a): return x**(a-1)*np.exp(-x) / scipy.special.gamma(a) _, ax = plt.subplots(1, 3, figsize=(14, 3.5)) x = np.linspace(0, 20, 1000) plot_gamma(gamma_pdf, x, 4, pdf=True, ax=ax[0], color=\u0026#39;C0\u0026#39;) plot_gamma(gamma_pdf, x, 6, pdf=True, ax=ax[1], color=\u0026#39;C1\u0026#39;) plot_gamma(gamma_pdf, x, 8, pdf=True, ax=ax[2], color=\u0026#39;C2\u0026#39;) plt.tight_layout() _, ax = plt.subplots(figsize=(6, 4)) x = np.linspace(0, 20, 1000) for i, a in enumerate((4, 6, 8)): y = gamma_pdf(x, a) ax.plot(x, y, color=f\u0026#39;C{i}\u0026#39;, label=f\u0026#39;{a=}\u0026#39;) ax.fill_between(x, y, color=f\u0026#39;C{i}\u0026#39;, alpha=.2) ax.set_xlabel(\u0026#39;x\u0026#39;) ax.set_title(\u0026#39;gamma_pdf(x; a)\u0026#39;) ax.legend(); Adding a scale parameter # Our pdf is neat, but can we do something more with it? Most distributions have two parameters, and we got only one: \\(a\\). Since more flexibility can always come in handy, why not add another one? What about adding a scaling \\(b\\) parameter?\nAccording to Wikipedia, this is pretty straightforward once we have a valid pdf, which we already do:\n\\[ scaled_{pdf}(x, b) = \\frac{1}{b}standard_{pdf}(\\frac{x}{b}) \\]\nIn our case\n\\[ gamma_{pdf}(x; a, b) = \\frac{(\\frac{x}{b})^{a-1} e^{-(\\frac{x}{b})}}{b \\Gamma(a)} \\]\nWhich we can arrange as\n\\[ gamma_{pdf}(x; a, b) = \\frac{x^{a-1} e^{-(\\frac{x}{b})}}{b^{a-1}b \\Gamma(a)} = \\frac{x^{a-1} e^{-(\\frac{x}{b})}}{b^{a} \\Gamma(a)} \\]\nOr alternatively, we can use a precision variable \\(c = \\frac{1}{b}\\)\n\\[ gamma_{pdf}(x; a, c) = \\frac{c(xc)^{a-1} e^{-(xc)}}{\\Gamma(a)} = \\frac{c^ax^{a-1} e^{-xc}}{\\Gamma(a)} \\]\nLet\u0026rsquo;s see what we can do with this extra parameter:\ndef gamma_pdf(x, a, c=1): return c**a * x**(a-1) * np.exp(-x*c) / scipy.special.gamma(a) def plot_gamma_variations(a, ax, color): x = np.linspace(0, 20, 1000) base_color = seaborn.saturate(color) for c, saturation in zip((2, 1, 0.5), (0.8, 0.4, 0.2)): y = gamma_pdf(x, a=a, c=c) color = seaborn.desaturate(base_color, saturation) ax.plot(x, y, color=color, label=f\u0026#39;{c=}\u0026#39;) ax.fill_between(x, y, color=color, alpha=.2) ax.set_xlabel(\u0026#39;x\u0026#39;) ax.set_title(f\u0026#39;$gamma_{{pdf}}(x;{a},c)$\u0026#39;) ax.legend() _, ax = plt.subplots(1, 3, figsize=(14, 3.5)) plot_gamma_variations(a=4, ax=ax[0], color=\u0026#39;C0\u0026#39;) plot_gamma_variations(a=6, ax=ax[1], color=\u0026#39;C1\u0026#39;) plot_gamma_variations(a=8, ax=ax[2], color=\u0026#39;C2\u0026#39;) plt.tight_layout() The parameter names \\(a\\), \\(b\\), and \\(c\\), deviate from traditional characterizations of the gamma distribution. Wikipedia, for example, uses \\(k\\) and \\(\\theta\\) for our \\(a\\) and scale \\(b\\), and a distinct pair of parameter names \\(\\alpha\\) and \\(\\beta\\) for our \\(a\\) and precision \\(c\\) parameterization. \\(\\lambda\\) is also commonly used for the precision parameter, as this is linked conceptually to the exponential \\(\\lambda\\) rate parameter. Speaking of which, \u0026ldquo;rate\u0026rdquo; is an alternative, and perhaps more common name, for \u0026ldquo;precision\u0026rdquo;. Bonus: deriving the CDF of the gamma distribution # We got the gamma pdf, let\u0026rsquo;s get the cumulative distribution function (CDF) as well. Recall that the CDF of a distribution \\(X\\) is the matematical function that returns the \\(P(X\u0026lt;=x)\\), that is the probability that the random \\(x\\) value is lower or equal to a specific number. Since it defines an interval, in our case \\([0, x]\\), it is appropriate to talk about probabilities and not just densities.\n\\[ gamma\\_cdf(x; a, c) = \\frac{\\int_0^x c^a(u)^{a-1} e^{-(cu)} du}{\\Gamma(a)}\\]\nNote that we need a new variable \\(u\\) to distinguish the limit of integration from the integrand. Also, for the very same reason as before, the \\(\\Gamma(a)\\) is there to make sure the CDF evaluates to \\(1\\) when \\(x=\\infty\\)\nThis article would have been slightly less unrealistic if it had started with the derivation of the CDF, since the Gamma integral function is what actually came down to us through history. def plot_gamma_integral(a, ax, color, cdf=False): x = np.logspace(0.1, 1.3) y = scipy.special.gammainc(a, x) assymptote = 1 # gammainc returns the already normalized incomplete integral gamma = scipy.special.gamma(a) y *= gamma ax.plot(x, y, color=color) ax.fill_between(x, y, color=color, alpha=.2) ax.set_yticks([gamma]) ax.grid(None, axis=\u0026#39;x\u0026#39;) ax.set_xlabel(\u0026#39;x\u0026#39;) ax.set_title(f\u0026#39;$\\int_0^{{x}}gamma(u; {a}, 1) du$\u0026#39;) _, ax = plt.subplots(1, 3, figsize=(14, 3.5)) plot_gamma_integral(4, ax=ax[0], color=\u0026#39;C0\u0026#39;) plot_gamma_integral(6, ax=ax[1], color=\u0026#39;C1\u0026#39;) plot_gamma_integral(8, ax=ax[2], color=\u0026#39;C2\u0026#39;) plt.tight_layout() _, ax = plt.subplots(figsize=(6, 4)) x = np.logspace(0.1, 1.3) for i, a in enumerate((4, 6, 8)): y = scipy.special.gammainc(a, x) ax.plot(x, y, color=f\u0026#39;C{i}\u0026#39;, label=f\u0026#39;{a=}\u0026#39;) ax.fill_between(x, y, color=f\u0026#39;C{i}\u0026#39;, alpha=.2) ax.set_xlabel(\u0026#39;x\u0026#39;) ax.set_title(f\u0026#39;$gamma_{{cdf}}(x; a, 1)$\u0026#39;) ax.legend(); The CDF expression can be further simplified with a change of variables \\(t = cu\\) \\[ \\begin{aligned} gamma\\_cdf(x; a, c) \u0026amp;= \\frac{\\int_0^x c^a(u)^{a-1} e^{-(cu)} du}{\\Gamma(a)} \\\\ \u0026amp;= \\frac{1}{\\Gamma(a)} \\int_0^x c(cu)^{a-1} e^{-(cu)} du \\\\ \u0026amp;= \\frac{1}{\\Gamma(a)} \\int_0^{xc} c(t)^{a-1} e^{-t} \\frac{1}{c}dt \\quad \\begin{cases} \\text{change of variables} \\\\ t = cu \\\\ dt = c\\,du \\\\ \\frac{1}{c}dt = du \\\\ \\end{cases} \\\\ \u0026amp;= \\frac{1}{\\Gamma(a)} \\int_0^{xc} t^{a-1} e^{-t} dt \\end{aligned} \\]\nWhich reveals that the inverse scaling by \\(c\\) has an effect on increasing or reducing the area of a standard gamma distribution that is contained below \\(x\\)\n_, ax = plt.subplots(figsize=(6, 4)) x = np.logspace(0.1, 1.6, 200) base_color = seaborn.saturate(\u0026#39;C0\u0026#39;) cutoff = 5 for c, saturation in zip( (1, 0.5, 0.25), (0.8, 0.4, 0.2) ): color = seaborn.desaturate(base_color, saturation) where = x\u0026lt;=(cutoff/c) y = scipy.special.gammainc(4, x*c) ax.plot(x[where], y[where], color=color, label=f\u0026#39;{c=}\u0026#39;) ax.plot(x[~where], y[~where], color=color, ls=\u0026#39;--\u0026#39;) ax.fill_between(x, y, where=where, color=color, alpha=.2) ax.set_xticks([5, 10, 20]) ax.set_yticks([0, scipy.special.gammainc(4, cutoff), 1]) ax.set_xlabel(\u0026#39;x\u0026#39;) ax.set_title(f\u0026#39;$gamma_{{cdf}}(x; 4, c)$\u0026#39;) # ax.set_ylabel(r\u0026#39;$\\frac{\\int_0^{xc}{f(a, u)} du}{area\\_f(x)}$\u0026#39;) ax.legend(); Similar to what we did with the pdf, it\u0026rsquo;s common to refactor the numerator integral expression into its own function. This is called lower incomplete gamma function, or more succintly the lower case gamma \\(\\gamma\\) letter. \\[ gamma\\_cdf(x; a, c) = \\frac{\\int_0^{xc} t^{a-1} e^{-t} dt}{\\Gamma(a)} = \\frac{\\gamma(a, xc)}{\\Gamma(a)} \\]\nAs with the gamma function, there are quick and stable numerical implementations of the incomplete gamma function. In scipy this can be obtained by scipy.special.gammainc(a, x) * scipy.special.gamma(a). The multiplication is needed because the default scipy.special.gammainc already contains the \\(gamma(a)\\) normalization term. Similarly to the gamma distribution, which gets its name from the gamma integral function \\(\\Gamma\\), the beta distribution also gets its name from the beta integral function \\(B\\). In fact the two distributions are closely related. nb2hugo ~/Documents/ricardoV94.github.io.website/raw_notebooks/gamma_distribution.ipynb --site-dir ~/Documents/ricardoV94.github.io.website/ --section posts "}]