[{"id":0,"href":"/posts/smc_basic_algorithm/","title":"A simple Sequential Monte Carlo algorithm for posterior approximation","section":"Blog","content":"Introduction #  Sequential Monte Carlo (SMC) can be used to take samples from posterior distributions, as an alternative to popular methods such as Markov Chain Monte Carlo (MCMC) like Metropolis-Hastings, Gibbs Sampling or more state-of-the-art Hamiltonian Monte Carlo (HMC) and No-U-Turn Sampler (NUTS).\nInstead of creating a single Markov Chain, SMC works by keeping track of a large population of samples, which, in a similar spirit to Genetic Algorithms can be \u0026ldquo;selected\u0026rdquo; and \u0026ldquo;mutated\u0026rdquo; to evolve a better \u0026ldquo;fit\u0026rdquo; to the posterior distribution.\nExperience suggests SMC is particularly well fit to the following settings:\n Multi-modal posterior distributions Online inference when data accumulates over time Approximate Bayesian Inference when the likelihood function cannot be easily written down  In this article I introduce the basic components that make up a simple SMC algorithm. In future articles, I present more complex variations that build up towards the specific algorithm that is employed in the PyMC3 library.\nToy 2D Gaussian example #  As with MCMC, SMC approximates the posterior distribution via careful weighted sampling. However, while MCMC approximates a distribution through a single random walk that unrolls over time, SMC does this in a parallel manner. At each step, it keeps track of a series of samples (also known as particles) that approximate the distribution as a whole.\nThis picture tries to illustrate this distinction for a simple 2D Gaussian posterior that will be used throughout this article:\n  \\(\\)  \\[ \\text{pdf}(x, y) = \\text{exp}(-\\begin{bmatrix}x\\\\ y\\end{bmatrix}^T \\begin{bmatrix}1\u0026amp;0.5\\\\ 0.5\u0026amp;1\\end{bmatrix}^{-1} \\begin{bmatrix}x\\\\ y\\end{bmatrix}) \\]\nApproximation to the 2D Gaussian posterior shown on the left plot. The middle plot shows the approximation from a single MCMC chain, with the samples connected sequentially, emphasizing the autocorrelated random walk behavior. The right plot shows the approximation from the SMC algorithm, where each sample is independent from the rest.\nWhy are we even doing this?\nThe example above with a 2D Gaussian is deceptively simple and there is no reason why we would need to use Monte Carlo approximations (be it MCMC or SMC) to understand it. Usually in the context of Bayesian data analysis we are working with a model that describes a complicated and highly dimensional posterior distribution that cannot be written down mathematically (or as mathematicians prefer, analytically).\nIn addition, even if the posterior distribution could be described mathematically, it is often very difficult to work with. We are usually interested in chopping the posterior distribution into a smaller number of components that we care about (marginalization) or summarizing it into metrics that are understandable such as correlations, averages and standard deviations (expectations). Surprisingly, these sort of operations are trivial if we can get a hold of a representative set of samples from the distribution in question. All we need is to do some smart indexing and call functions such as numpy.mean() and numpy.std()!\n The core of the SMC algorithm is very simple:\n We start by creating a large population of particles, usually by sampling from the prior distribution. We then compute a weight for each particle, which is proportional to the posterior probability at that \u0026ldquo;point\u0026rdquo;. These weights are used to sample, with replacement, a new population of particles. This will lead to a population that is more representative of the posterior distribution. On average, a particle that is 3x more probable than another will be resampled 3x as often. Finally, we introduce some \u0026ldquo;mutations\u0026rdquo; in the population. This could be as simple as adding a random uniform jittering to each particle dimension, but, we can also try to \u0026ldquo;guide\u0026rdquo; the particles in a more clever way towards areas of larger posterior mass.  The pseudocode for the SMC algorithm is given below:\n# hyperparameters n_particles = 2000 n_steps = 10 # initialize population of particles from prior particles = sample_prior(n_particles) # main loop for step in range(n_steps): # compute particle weights in proportion # to the posterior distribution probability weights = compute_weights(particles, posterior) # resample particles (with replacement) # based on their weights particles = resample(particles, weights) # mutate particles to reintroduce variation # and better explore the posterior distribution particles = mutate(particles) # final approximation is given by the final particles posterior = particles   Let\u0026rsquo;s flesh out these steps in detail.\nA particle is born #  What is a particle?\nA particle (or a sample in conventional MCMC) is a numerical vector with one entry for each parameter in the posterior function that we are interested in. In the 2D Gaussian example above it was a 2D-vector with {x, y} coordinates.\nparticle = {\u0026quot;x\u0026quot;: -0.5, \u0026quot;y\u0026quot;: 0.2}  In a simple linear regression model it might be an \\(N^D\\)-vector containing a value for the intercept, a coefficient for each predictor in our dataset and a noise term for the observations.\nparticle = {\u0026quot;intercept\u0026quot;: 1.0, \u0026quot;coef_1\u0026quot;: 0.5, \u0026quot;coef_2\u0026quot;: 0.2, \u0026quot;noise\u0026quot;: 3.0}   import numpy as np import scipy.stats as st import matplotlib.pyplot as plt import seaborn as sns sns.set_style(\u0026#34;dark\u0026#34;) sns.set(font_scale = 1.4) def create_plot(rows=1, cols=1): fig, ax = plt.subplots(rows, cols, figsize=(6*cols, 6*rows), sharex=True, sharey=True) # single plot if rows + cols == 2: ax.set_aspect(\u0026#39;equal\u0026#39;, \u0026#39;box\u0026#39;) ax.set_xticks([]) ax.set_yticks([]) # multiple plot else: for axi in ax.ravel(): axi.set_aspect(\u0026#39;equal\u0026#39;, \u0026#39;box\u0026#39;) axi.set_xticks([]) axi.set_yticks([]) return fig, ax def make_arrow(a, b, axA, axB): from matplotlib.patches import ConnectionPatch return ConnectionPatch( a, b, coordsA=\u0026#34;axes fraction\u0026#34;, coordsB=\u0026#34;axes fraction\u0026#34;, axesA=axA, axesB=axB, color=\u0026#34;k\u0026#34;, fc=\u0026#34;k\u0026#34;, arrowstyle=\u0026#34;-|\u0026gt;\u0026#34;, mutation_scale=30, lw=2, zorder=10, ) Let\u0026rsquo;s create our very first particles:\nclass Particle: def __init__(self, x, y): self.x = x self.y = y adam, eve = Particle(x=1, y=0), Particle(x=0, y=1)   _, ax = create_plot() ax.scatter(adam.x, adam.y) ax.annotate(\u0026#34;Adam\u0026#34;, (adam.x, adam.y+.1), ha=\u0026#34;center\u0026#34;, fontsize=16) ax.scatter(eve.x, eve.y) ax.annotate(\u0026#34;Eve\u0026#34;, (eve.x, eve.y+.1), ha=\u0026#34;center\u0026#34;, fontsize=16) ax.set_xlim([-0.5, 1.5]) ax.set_ylim([-0.5, 1.5]); Kidding aside, we need to get a whole population of particles. How should we choose?\nMaking the effort to pick a good initial population can be very useful. Remember that the goal is to obtain a representative sample from the posterior distribution, and so the closer our initial population is to the posterior, the closer we are to being done.\nRegardless, and to keep things simple with our toy example, we will just take a random sample from the uniform grid:\ndef sample_uniform_grid(min_x, max_x, min_y, max_y, n): particles = [] for i in range(n): x = np.random.uniform(min_x, max_x) y = np.random.uniform(min_y, max_y) particle = Particle(x=x, y=y) particles.append(particle) return particles   particles = sample_uniform_grid(-3, 3, -3, 3, n=1000) xs = [particle.x for particle in particles] ys = [particle.y for particle in particles] _, ax = create_plot() ax.scatter(xs, ys, alpha=0.3) ax.set_title(\u0026#34;The prior population\u0026#34;); Picking favorites #  Now that we have a population of particles, it\u0026rsquo;s time to evolve it into a proper approximation of the posterior distribution! To do this, we weight each particle by its posterior probability, normalize all the population weights so that they add up to 1.0 and use them to resample with replacement.\ndef posterior(particle): \u0026#34;\u0026#34;\u0026#34; Unnormalized 2D Gaussian with [0, 0] mean and [[0.5, 1.0], [1.0, 0.5]] covariance matrix \u0026#34;\u0026#34;\u0026#34; xy = np.array([particle.x, particle.y]) cov = np.array([[1.0, 0.5], [0.5, 1.0]]) return np.exp(-(xy) @ np.linalg.inv(cov) @ (xy)) def compute_weights(particles, posterior): weights = np.array([posterior(particle) for particle in particles]) weights /= np.sum(weights) # normalize weights return weights def resample(particles, weights): idxs = np.arange(len(particles)) sampled_idxs = np.random.choice(idxs, p=weights, replace=True, size=len(particles)) resampled_particles = [] for idx in sampled_idxs: resampled_particles.append(particles[idx]) return resampled_particles   _, ax = create_plot(1, 3) xs = [particle.x for particle in particles] ys = [particle.y for particle in particles] ax[0].scatter(xs, ys, alpha=0.2) ax[0].set_title(\u0026#34;Initial particles\u0026#34;) weights = compute_weights(particles, posterior) rescaled_weights = 0.95 * (weights - np.min(weights)) / (np.max(weights) - np.min(weights)) + 0.05 ax[1].scatter(xs, ys, s=150 * rescaled_weights, alpha=0.2, color=\u0026#34;C3\u0026#34;) ax[1].set_title(\u0026#34;Particle weights\u0026#34;) resampled_particles = resample(particles, weights) xs = [particle.x for particle in resampled_particles] ys = [particle.y for particle in resampled_particles] ax[2].scatter(xs, ys, s=50, alpha=0.2) ax[2].set_title(\u0026#34;Resampled particles\u0026#34;) ax[1].add_artist(make_arrow((0.85, 0.5), (0.15, 0.5), ax[0], ax[1])); ax[2].add_artist(make_arrow((0.85, 0.5), (0.15, 0.5), ax[1], ax[2])); The initial population of particles is shown on the left plot. In the middle plot each particle is given a weight proportional to its posterior probability. The weights are illustrated by the particle size. In the right plot, the particles were resampled with replacement based on their weights. Each particle is plotted with the same transparency, and those resampled multiple times appear to be darker.\nIntroducing variation #  The example above was a favorable one, where the initial population of particles happened to cover the bulk of the posterior distribution. We may not always be this lucky, for instance when working with very complex distributions or when our choice for initial population of particles is not great, as in the exaggerated example below:\n_, ax = create_plot(1, 3) ax[0].set_xlim([-3, 3]) ax[0].set_ylim([-3, 3]) bad_particles = sample_uniform_grid(-3, 0, -3, 0, 500) xs = [particle.x for particle in bad_particles] ys = [particle.y for particle in bad_particles] ax[0].scatter(xs, ys, alpha=0.2) ax[0].set_title(\u0026#34;Initial particles\u0026#34;) weights = compute_weights(bad_particles, posterior) rescaled_weights = 0.95 * (weights - np.min(weights)) / (np.max(weights) - np.min(weights)) + 0.05 ax[1].scatter(xs, ys, s=150 * rescaled_weights, alpha=0.2, color=\u0026#34;C3\u0026#34;) ax[1].set_title(\u0026#34;Particle weights\u0026#34;) bad_resampled_particles = resample(bad_particles, weights) xs = [particle.x for particle in bad_resampled_particles] ys = [particle.y for particle in bad_resampled_particles] ax[2].scatter(xs, ys, s=50, alpha=0.2) ax[2].set_title(\u0026#34;Resampled particles\u0026#34;) ax[1].add_artist(make_arrow((0.85, 0.5), (0.15, 0.5), ax[0], ax[1])); ax[2].add_artist(make_arrow((0.85, 0.5), (0.15, 0.5), ax[1], ax[2])); To obtain a robust algorithm we need some way for the population to \u0026ldquo;evolve\u0026rdquo; towards the target distribution. This is achieved by mutating the particles.\nThe mutation step is also important for reintroducing variability after the resampling step. Because resampled particles are exact copies of each other, if we were to rerun the weighting and resampling steps several times, the population would quickly converge to a singular particle.\nBlind evolution #  The simplest mutation strategy is to add a random offset to each particle parameter:\ndef random_mutation(particles): new_particles = [] for particle in particles: # Add Gaussian noise around each particle dimension new_x = particle.x + np.random.normal(0, .2) new_y = particle.y + np.random.normal(0, .2) new_particle = Particle(x=new_x, y=new_y) new_particles.append(new_particle) return new_particles   _, ax = create_plot(1, 4) ax[0].set_xlim([-3, 3]) ax[0].set_ylim([-3, 3]) particles = bad_resampled_particles xs = [particle.x for particle in particles] ys = [particle.y for particle in particles] ax[0].scatter(xs, ys, alpha=0.2) ax[0].set_title(\u0026#34;Resampled particles\u0026#34;) particles = random_mutation(particles) new_xs = [particle.x for particle in particles] new_ys = [particle.y for particle in particles] ax[1].scatter(new_xs, new_ys, alpha=0.2) ax[1].set_title(\u0026#34;Mutated particles\u0026#34;) weights = compute_weights(particles, posterior) particles = resample(particles, weights) xs = [particle.x for particle in particles] ys = [particle.y for particle in particles] ax[2].scatter(xs, ys, alpha=0.2) ax[2].set_title(\u0026#34;Resampled particles\u0026#34;) particles = random_mutation(particles) new_xs = [particle.x for particle in particles] new_ys = [particle.y for particle in particles] ax[3].scatter(new_xs, new_ys, alpha=0.2) ax[3].set_title(\u0026#34;Mutated particles\u0026#34;) ax[1].add_artist(make_arrow((0.85, 0.5), (0.15, 0.5), ax[0], ax[1])); ax[2].add_artist(make_arrow((0.85, 0.5), (0.15, 0.5), ax[1], ax[2])); ax[3].add_artist(make_arrow((0.85, 0.5), (0.15, 0.5), ax[2], ax[3])); Intelligent design #  Creationists might have gotten it wrong when it comes to natural selection, but their premise makes a lot of sense: It would all have been much easier if someone had taken the driving seat. Fortunately that is something we can do in SMC, and in particular when it comes to how we mutate the population of particles.\nInstead of using a blind form of \u0026ldquo;mutation\u0026rdquo; as above, we can intelligently drive the particles towards areas of high probability in the posterior distribution. One way of doing this is to run each particle through a traditional MCMC algorithm for a specific number of steps and take the final position as the new mutated particle.\ndef metropolis_hastings_mutation(particles): # This should be parallelized new_particles = [] for particle in particles: new_particle = single_particle_mh(particle, steps=10) new_particles.append(new_particle) return new_particles def single_particle_mh(particle, steps): \u0026#34;\u0026#34;\u0026#34; Run a small Metropolis-Hastings MCMC chain around a single particle \u0026#34;\u0026#34;\u0026#34; # The proposal distribution should be tuned proposal_distribution = st.norm(0, .2) for step in range(steps): x_offset, y_offset = proposal_distribution.rvs(2) new_particle = Particle( x=particle.x + x_offset, y=particle.y + y_offset, ) # Compute Metropolis-Hastings jump probability given the ratio # between current and proposed particle probability current_probability = posterior(particle) proposed_probability = posterior(new_particle) jump_probability = min(1, proposed_probability / current_probability) if jump_probability \u0026gt;= np.random.rand(): particle = new_particle else: particle = particle return particle   _, ax = create_plot(1, 4) ax[0].set_xlim([-3, 3]) ax[0].set_ylim([-3, 3]) particles = bad_resampled_particles xs = [particle.x for particle in particles] ys = [particle.y for particle in particles] ax[0].scatter(xs, ys, alpha=0.2) ax[0].set_title(\u0026#34;Resampled particles\u0026#34;) particles = metropolis_hastings_mutation(particles) new_xs = [particle.x for particle in particles] new_ys = [particle.y for particle in particles] ax[1].scatter(new_xs, new_ys, alpha=0.2) ax[1].set_title(\u0026#34;Mutated particles\u0026#34;) weights = compute_weights(particles, posterior) particles = resample(particles, weights) xs = [particle.x for particle in particles] ys = [particle.y for particle in particles] ax[2].scatter(xs, ys, alpha=0.2) ax[2].set_title(\u0026#34;Resampled particles\u0026#34;) particles = random_mutation(particles) new_xs = [particle.x for particle in particles] new_ys = [particle.y for particle in particles] ax[3].scatter(new_xs, new_ys, alpha=0.2) ax[3].set_title(\u0026#34;Mutated particles\u0026#34;) ax[1].add_artist(make_arrow((0.85, 0.5), (0.15, 0.5), ax[0], ax[1])); ax[2].add_artist(make_arrow((0.85, 0.5), (0.15, 0.5), ax[1], ax[2])); ax[3].add_artist(make_arrow((0.85, 0.5), (0.15, 0.5), ax[2], ax[3])); The population progressed much faster towards the target distribution.\nSummary #  To summarize, here is the basic SMC algorithm again:\n# hyperparameters n_particles = 2000 n_steps = 10 # initialize population of particles from prior particles = sample_prior(n_particles) # main loop for step in range(n_steps): # compute particle weights in proportion # to the posterior distribution probability weights = compute_weights(particles, posterior) # resample particles (with replacement) # based on their weights particles = resample(particles, weights) # mutate particles to reintroduce variation # and better explore the posterior distribution particles = mutate(particles) # final approximation is given by the final particles posterior = particles   What about the prior? #  You might have noticed a large repetition of the word \u0026ldquo;posterior\u0026rdquo;, and a strange absence of \u0026ldquo;prior\u0026rdquo;. To keep things simple I chose to work with an implicitly uniform prior which does not affect the posterior calculations. Indeed the two are needed for a complete Bayesian inference. And in fact there is something very interesting that can be done when combining the two into a general SMC algorithm. That\u0026rsquo;s the topic of the [next article]!\nnb2hugo raw_notebooks/smc_basic_algorithm.ipynb --site-dir . --section posts  "},{"id":1,"href":"/posts/hello-world/","title":"Hello, World","section":"Blog","content":"Introduction #  Not much to see here\n"},{"id":2,"href":"/topics/gsoc-2021/proposal/","title":"Proposal","section":"Gsoc 2021","content":"PyMC3: Make SMC-ABC faster and more flexible #  Intro #  PyMC3 provides state-of-the-art tools to specify rich mathematical probabilistic models and algorithms to efficiently approximate the posterior distribution of such models conditioned on observed data. One such algorithm is the Sequential Monte Carlo (SMC) sampler which is capable of drawing samples from complex posterior distributions (e.g., multimodal distributions).\nIn addition to traditional Bayesian inference, SMC can also be used to perform Approximate Bayesian Computation (ABC), which allows one to define models without a pure mathematical likelihood term, which is difficult to derive in many complex real world problems. To achieve this, SMC-ABC makes use of a “Simulator” function that is capable of returning simulated observed data given different unobserved parameters.\nThis project seeks to extend the documentation, performance and flexibility of SMC and SMC-ABC sampling in PyMC3, to make it competitive with specialized libraries while remaining accessible to the large user-base of the PyMC3 library.\nTechnical Details #  This project involves making improvements to the SMC(-ABC) sampler in the light of the recent changes to the Aesara backend in the upcoming V4 release. This ongoing transition involves a large change to the library codebase and it is likely that some features of SMC(-ABC) may be broken in the process.\nPhase 1 #  Weeks 1 - 3 (June 7th - June 27th)\nAs such, the first phase of the project will focus on fixing any potential regressions, while aligning the code logic to be more in line with the core library after the V4 transition. Some prior issues that were detected through personal experimentation and user discussions will also be tackled during this initial phase:\n Wrap the pm.Simulator object around RandomOps for a more consistent integration within the PyMC3 model object Fix currently broken Prior and Posterior predictive sampling when using pm.Simulator Fix currently broken graphviz representation when using Pm.Simulator Allow pm.Simulator wrapped function to take non-named inputs and provide more useful error messages for improper initialization (see discourse issue) Add progress bar in each beta stage for better visual feedback of sampling speed during SMC Automatically select SMC-ABC when pm.Simulator is present in a Model object Fix missing documentation for pm.Simulator Test possibility for improved performance via vectorized evaluation of the graph logp across SMC particles Test parallel sampling in SMC and provide that as default.  Phase 2 #  Weeks 4-6 (June 28th - July 18th)\nIn the second phase of this project, the core SMC-ABC functions will be refactored to increase its modularity and facilitate the implementation and testing of different algorithms going into the future. During this time I also plan to write 3 in-depth PyMC-examples that demonstrate the use of SMC(-ABC) in PyMC3. These include:\n Definition of a consistent API based on python functions with standard I/O that can be plugged in at the different stages of SMC: initialize_population, mutate, tune, etc\u0026hellip; for customization of the sampling algorithm. Provide two standard SMC algorithms: Independent MvNormal (already implemented in v3), and Normal random walk (reintroduced for benchmarking and assessing modularity of the SMC-ABC functionality) Add a Probability Density Approximation (PDA) method based on a Gaussian or Epanechnikov kernel as an alternative to the epsilon based distance Pseudo-likelihood (Turner \u0026amp; Sederberg, 2014). Documentation for all changes Write 3 new PyMC-examples that illustrate SMC(-ABC) features:  Adapt and extend toy example from Bååth (2014) which emphasizes the advantages and disadvantages of ABC sampling (need to derive complex likelihoods vs speed / accuracy). Contrast the accuracy of ABC vs true-likelihood sampling in simple Cognitive research models with known Likelihood forms described in Palestro et al., (2018). Tutorial on how to implement a custom SMC-kernel (Independent Metropolis Hastings with mixture of gaussians) to facilitate future research and development of SMC(-ABC) in PyMC3.    Phase 3 #  Weeks 7-10 (July 19th - August 15th)\nThe third and final phase of the project will explore promising extensions of SMC(-ABC) beyond what is currently offered in the PyMC3 library. Namely:\n Proof of concept SMC sampling with NUTS kernel for updating of particles. Combination of Simulator with normal NUTS blocked sampling by updating first order parameters with the ABC Pseudolikelihood, and hyperparameters that do not feed directly into the (Pseudo-)Likelihood with NUTS (a.k.a, Hierarchical Gibbs Sampling, see Turner \u0026amp; van Zandt, 2014) Allow for multiple Simulators within a single model (e.g., in a hierarchical model where one might want to use different epsilon levels for different observations/ users) Allow the Mixing of Simulator Pseudo-likelihoods and True-likelihoods in a single model.  Community Bonding Period #  (May 17 - June 7)\nI plan to make use of the Community Bonding Period to further refine the goals of my project with the supervisors and core-developer team. During this time I plan to reach out to the PyMC3 user community (via https://discourse.pymc.io/) to elicit feedback and suggestions on the proposal. Finally, during this phase I will launch a monthly code-sharing “contest” where users can submit and review PyMC3 models that highlight interesting library features as well as general statistical and theoretical ideas that arise in the practice of bayesian modelling and inference.\nWhy Me? #  I am a PhD Student in the field of Cognitive Science, and enthusiast self-taught statistician. I am interested in the features of Bayesian models not only as a useful statistical tool for research data analysis but also as a model of human and animal cognition. In addition, I am a fan of the Python language and I have been learning, using it and teaching it for 6 years. Development Experience\nI have been an active contributor to the PyMC3 library since last December, having used the library extensively in research for nearly 2 years now. I became an official core-developer around January 2021, and I have engaged with the project and community extensively since and prior to that. A few of my (merged) PRs are listed below:\nNew functionalities:\n #4419: Add informative user Warning when doing prior/posterior predictive sampling in models with arbitrary Potentials #4407: Increase numerical stability of ExGaussian logp and logcdf methods #4387: Implement logcdf methods for discrete distributions #4373: Complete stale DirichletMultinomial distribution PR #4360: Improve math.logsumexp to work with infinite values #4298: Make jitter during initializations of NUTS more robust #4134: Add parameterizations to NegativeBinomial in terms of n and p  Testing:\n #4461: Unseed wrongly seeded tests #4448: Add tests for difficult to debug bugs #4393: Make logcdf tests more exhaustive  Minor bugfixes:\n #4366 #4211  Why PyMC3? #  PyMC3 provides easy access to state-of-the-art tools to perform Bayesian inference. I have used this library extensively during my research and teaching, and found it invaluable within the Python (and Bayesian) ecosystem. It’s simple syntax, extensive documentation and large active community make it easy for beginners to transition into Bayesian analysis, which is increasingly viewed as a more principled and more fool-proof way of performing statistical analysis and informed decision making in research and industry settings.\nReferences #   Bååth, R (2014). Tiny Data, Approximate Bayesian Computation and the Socks of Karl Broman. http://www.sumsar.net/blog/2014/10/tiny-data-and-the-socks-of-karl-broman/ Palestro, J. J., Sederberg, P. B., Osth, A. F., Van Zandt, T., \u0026amp; Turner, B. M. (2018). Likelihood-free methods for cognitive science. Springer International Publishing. Turner, B. M., \u0026amp; Sederberg, P. B. (2014). A generalized, likelihood-free method for posterior estimation. Psychonomic bulletin \u0026amp; review, 21(2), 227-250. Turner, B. M., \u0026amp; Van Zandt, T. (2014). Hierarchical approximate Bayesian computation. Psychometrika, 79(2), 185-209.  "}]